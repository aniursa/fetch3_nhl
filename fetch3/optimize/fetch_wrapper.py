"""
Optimization wrapper for FETCH3.

These functions provide the interface between the optimization tool and FETCH3
- Setting up optimization experiment
- Creating directories for model outputs of each iteration
- Writing model configuration files for each iteration
- Starting model runs for each iteration
- Reading model outputs and observation data for model evaluation
- Defines objective function for optimization, and other performance metrics of interest
- Defines how results of each iteration should be evaluated
"""

import atexit
import datetime as dt
import os
import subprocess
from pathlib import Path
import logging

from pprint import pformat

logger = logging.getLogger(__name__)

import numpy as np
import pandas as pd
import xarray as xr
import yaml
from ax import Trial
from boa import (
    BaseWrapper,
    cd_and_cd_back,
    get_trial_dir,
    make_trial_dir
)

from fetch3.scaling import convert_trans_m3s_to_cm3hr


def read_experiment_config(config_file):
    """
    Read experiment configuration yml file for setting up the optimization.
    yml file contains the list of parameters, and whether each parameter is a fixed
    parameter or a range parameter. Fixed parameters have a value specified, and range
    parameters have a range specified.

    Parameters
    ----------
    config_file : str
        File path for the experiment configuration file

    Returns
    -------
    params: list
        Parameters formatted for the Ax experiment
    experiment_settings: dict
        Optimization options for the experiment
    """

    # Load the experiment config yml file
    with open(config_file, "r") as yml_config:
        loaded_configs = yaml.safe_load(yml_config)

    # Format parameters for Ax experiment
    for param in loaded_configs["parameters"].keys():
        # Add "name" attribute for each parameter
        loaded_configs["parameters"][param]["name"] = param
    # Parameters from dictionary to list
    params = [loaded_configs["parameters"][param] for param in list(loaded_configs["parameters"])]
    experiment_settings = loaded_configs["optimization_options"]
    model_settings = loaded_configs["model_options"]
    return params, experiment_settings, model_settings





def write_configs(trial_dir, parameters, model_options):
    """
    Write model configuration file for each trial (model run). This is the config file used by FETCH3
    for the model run.

    The config file is written as ```config.yml``` inside the trial directory.

    Parameters
    ----------
    trial_dir : Path
        Trial directory where the config file will be written
    parameters : list
        Model parameters for the trial, generated by the ax client
    model_options : dict
        Model options loaded from the experiment config yml file.

    Returns
    -------
    str
        Path for the config file
    """
    with open(trial_dir / "config.yml", "w") as f:
        # Write model options from loaded config
        # Parameters for the trial from Ax
        config_dict = {"model_options": model_options, "parameters": parameters}
        yaml.dump(config_dict, f)
        return f.name


def get_model_sapflux(modelfile, obsfile, obs_var, output_var, **kwargs):
    """
    Read in observation data model output for a trial, which will be used for
    calculating the objective function for the trial.

    Parameters
    ----------
    modelfile : str
        File path to the model output
    obsfile : str
        File path to the observation data
    model_settings: dict
        dictionary with model settings read from model config file

    Returns
    -------
    model_output: pandas Series
        Model output
    obs: pandas Series
        Observations

    ..todo::
        * Add options to specify certain variables from the observation/output files
        * Add option to read from .nc file

    """
    # Read config file

    # Read in observation data
    obsdf = pd.read_csv(obsfile, parse_dates=[0])
    # Converting time since sapfluxnet data is in GMT
    obsdf["Timestamp"] = obsdf.TIMESTAMP.dt.tz_convert("EST")
    obsdf = obsdf.set_index("Timestamp")

    # Read in model output
    modeldf = xr.load_dataset(modelfile)
    modeldf = modeldf.sel(species=output_var)

    # Slice met data to just the time period that was modeled
    obsdf = obsdf.loc[modeldf.time.data[0] : modeldf.time.data[-1]]

    # Convert model output to the same units as the input data
    # Sapfluxnet data is in cm3 hr-1
    modeldf["sapflux_scaled"] = convert_trans_m3s_to_cm3hr(modeldf.sapflux)

    # remove first and last timestamp
    obsdf = obsdf.iloc[1:-1]
    modeldf = modeldf.sapflux_scaled.isel(time=np.arange(1, len(modeldf.time) - 1))

    not_nans = ~obsdf[obs_var].isna()
    obsdf_not_nans = obsdf[obs_var].loc[not_nans]
    modeldf_not_nans = modeldf.data[not_nans]

    return modeldf_not_nans, obsdf_not_nans


def scale_sapflux(sapflux, dz, mean_crown_area_sp, total_crown_area_sp, plot_area):
    """Scales sapflux from FETCH output (in kg s-1) to W m-2"""
    scaled_sapflux = sapflux * 2440000 / mean_crown_area_sp * total_crown_area_sp / plot_area
    return scaled_sapflux


def scale_transpiration(trans, dz, mean_crown_area_sp, total_crown_area_sp, plot_area):
    """Scales transpiration from FETCH output (in m H20 m-2crown m-1stem s-1) to W m-2"""
    scaled_trans = (trans * 1000 * dz * 2440000 * total_crown_area_sp / plot_area).sum(
        dim="z", skipna=True
    )
    return scaled_trans


class Fetch3Wrapper(BaseWrapper):
    _processes = []
    config_file_name = "config.yml"
    fetch_data_funcs = {get_model_sapflux.__name__: get_model_sapflux}

    def __init__(self):
        self.ex_settings: dict = None
        self.model_settings: dict = None
        self.experiment_dir: os.PathLike = None
        self.mapping: dict = None

    def load_config(self, config_file: os.PathLike):
        """
        Load config file and return a dictionary # TODO finish this

        Parameters
        ----------
        config_file : os.PathLike
            File path for the experiment configuration file

        Returns
        -------
        loaded_config: dict
        """
        # Load the experiment config yml file
        with open(config_file, "r") as yml_config:
            config = yaml.safe_load(yml_config)

        self.ex_settings = config["optimization_options"]
        self.model_settings = config["model_options"]

        site_parameters = config["site_parameters"]
        species_parameters = config["species_parameters"]

        parameters = {}
        mapping = {}
        for species, params in species_parameters.items():
            for parameter, dct in params.items():
                new_key = f"{species}_{parameter}"
                parameters[new_key] = dct
                mapping[new_key] = species
        self.mapping = mapping

        parameters.update(site_parameters)
        config["parameters"] = parameters
        logging.info(pformat(config))
        return config

    def write_configs(self, trial: Trial) -> None:
        """
        Write model configuration file for a trial (model run). This is the config file used by FETCH3
        for the model run.

        The config file is written as ```config.yml``` inside the trial directory.

        Parameters
        ----------
        trial: Trial
            The trial to deploy.

        Returns
        -------
        str
            Path for the config file
        """
        trial_dir = make_trial_dir(self.experiment_dir, trial.index)
        parameters = trial.arm.parameters

        species_parameters = {}
        site_parameters = {}
        for parameter, dct in parameters.items():
            if parameter in self.mapping:
                species = self.mapping[parameter]
                if species not in species_parameters:
                    species_parameters[species] = {}

                new_key = parameter[len(species)+1:] if species in parameter else parameter
                species_parameters[species][new_key] = dct
            else:
                site_parameters[parameter] = dct

        model_options = self.model_settings
        config_dict = {
            "model_options": model_options,
            "site_parameters": site_parameters,
            "species_parameters": species_parameters
        }
        logging.info(pformat(config_dict))
        with open(trial_dir / self.config_file_name, "w") as f:
            # Write model options from loaded config
            # Parameters for the trial from Ax
            yaml.dump(config_dict, f)
            return f.name

    def run_model(self, trial: Trial):

        trial_dir = get_trial_dir(self.experiment_dir, trial.index)
        config_path = trial_dir / self.config_file_name

        model_dir = self.ex_settings["model_dir"]

        # with cd_and_cd_back(model_dir):
        os.chdir(model_dir)

        cmd = (
            f"python main.py --config_path {config_path} --data_path"
            f" {self.ex_settings['data_path']} --output_path {trial_dir}"
        )

        args = cmd.split()
        popen = subprocess.Popen(args, stdout=subprocess.PIPE, universal_newlines=True)
        self._processes.append(popen)

    def set_trial_status(self, trial: Trial) -> None:
        """ "Get status of the job by a given ID. For simplicity of the example,
        return an Ax `TrialStatus`.
        """
        log_file = get_trial_dir(self.experiment_dir, trial.index) / "fetch3.log"

        if log_file.exists():
            with open(log_file, "r") as f:
                contents = f.read()
            if "Error completing Run! Reason:" in contents:
                trial.mark_failed()
            elif "run complete" in contents:
                trial.mark_completed()

    def fetch_trial_data(self, trial: Trial, metric_properties: dict, metric_name: str, *args, **kwargs):

        modelfile = (
            get_trial_dir(self.experiment_dir, trial.index) / self.ex_settings["output_fname"]
        )

        obs_file = metric_properties["obs_file"]
        obs_var = metric_properties["obs_var"]
        output_var = metric_properties["output_var"]
        fetch_data_func = self.fetch_data_funcs[metric_properties["fetch_data_func"]]

        y_pred, y_true = fetch_data_func(
            modelfile,
            **metric_properties
        )
        return dict(y_pred=y_pred, y_true=y_true)


def exit_handler():
    for process in Fetch3Wrapper._processes:
        process.kill()


atexit.register(exit_handler)
